/**
 *
 * @mainpage Team 3
 *
 * @author Leonhard Kuboschek (kuboschek)
 * @author Felix Schmoll (LiftnLearn)
 * @author Maria Gladkova (mgladkova)
 *
 * ## Team members
 *
 *  * Maria Gladkova (mgladkova)
 *  * Leonhard Kuboschek (kuboschek)
 *  * Felix Schmoll (LiftnLearn)
 *
 * ## External dependencies
 *  * ```OpenCV (2.4.8)```
 *  * ```ROS (indigo)```
 *  * ```gtest (1.6.0)```
 *
 *
 * ## Contained packages
 *
 *  - ```half_circle_detection``` to convert laser data into circle positions
 *  - ```movement``` base package to define a robot class, track and publish its movement
 *  - ```wall_following_strategy``` to drive the robot through the maze along walls
 *  - ```line_detection``` to detect lines in the laser scan data
 *  - ```corner_handling``` to unstick the robot in tight corners
 *  - ```crash_recovery``` to recover from unplanned impact with walls
 *
 * ### Half circle detection
 *  The general idea is that the ```laserScan```-data are received by the
 * ```half_circle_detection```-package and it is processing whether it can find a
 * half-circle. It then publishes its result on another topic. It has currently
 * only been tested in the simulator.
 *
 * ### Wall Following Strategy
 * The ```wall_following_strategy``` package contains the strategy node,
 * which takes inputs from the line detector, the corner handling, and the
 * crash recovery module, to follow walls until a circle is seen. Once a circle
 * has been seen, the strategy drives the robot straight toward it.
 *
 * ### Line Detection
 * The line detector generates a list of line segments  from laser scan data using the probabilistic Hough transform.
 *
 * ### Corner Handling
 * The corner handling node analyzes the laser scan to determine if the robot is
 * stuck in a space that it can't turn around in. It is currently not majorly used.
 *
 * ### Crash Recovery
 * The crash recovery node performs a 'reverse-and-turn' maneuver if the robot
 * impacts with its surrounding. 
 * 
 * ## Further comments
 * The individual contributions of the team members were so far quite heterogeneous.
 * Further improvement on team collaboration and integration of pair programming
 * needs to be considered in the future work. The test coverage is low at the moment, although it has been increased since the last sprint. We need to significantly improve the half-circle detection and line detection for the usage with significant error like it will be in the real robot.
 *
 * We would also like to thank the TAs. Keep up the good work!
 *
 */
